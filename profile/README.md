# [AI Security Research Lab at Miami University](https://miamioh.edu/profiles/cec/samer-khamaiseh.html)
<p align="center">
  <img src="https://github.com/user-attachments/assets/02dae6e8-da7e-4c07-b5fe-4013d2d4dda6" width = 512 />
</p>

## ğŸ‘‹ **Welcome to the Laboratory of AI Security Research (LAiSR) at Miami University.**
The rapid proliferation of artificial intelligence (AI) has revolutionized our world, but it also brings forth critical security challenges. As organizations harness AIâ€™s power, they must grapple with new vulnerabilities and potential risks. From automated cyberattacks to disinformation campaigns, the stakes are high.
## â“ Why researching in **AI securtiy** is of paramount importanc?
- Emerging Threats: As AI systems become more pervasive, so do the risks. From adversarial attacks on machine learning models to privacy breaches, understanding and mitigating these threats is crucial. Researchers play a pivotal role in uncovering vulnerabilities and devising robust defenses.
- Safeguarding Critical Systems: AI is increasingly integrated into critical infrastructure, healthcare, finance, and defense. Ensuring the security of these systems is non-negotiable. Rigorous research helps prevent catastrophic failures and protects lives and livelihoods.
- Ethical Implications: AI decisions impact individuals and societies. Bias, fairness, and transparency are ethical concerns. Research informs guidelines and policies that promote responsible AI deployment, minimizing harm and maximizing benefits.

## ğŸ¤ Who we are? 
**LAiSR** is a dynamic research group led by **Dr. Samer Khamaiseh**. We are passionately dedicated to exploring and addressing the evolving challenges within the realm of AI security. Our AI Research Laboratory is at the forefront of cutting-edge research to fortify AI models against adversarial attacks, enhance their robustness, and ensure their reliability in real-world scenarios.

## ğŸ” Research Focus
- **Robustness:** We delve into techniques that make AI models resilient to perturbations, adversarial examples, and distribution shifts.
- **Security:** Exploring defenses against attacks, privacy preservation, and secure AI deployment.
- **AI Ethics:** Investigate fairness, bias mitigation, and transparency in AI systems.

## ğŸš€ Projects
### **Fool-X**
[Add descreption]
### **Image Patriot**
[Add descreption]
### **target-X**
[Add descreption]
### **ADT++**
A novel method for adversarial training.
### **VariousAttacks**
A novel method for adversarial training.

# ğŸ“¸ Gallery
<p float="left">
  <img src="https://github.com/user-attachments/assets/4ba8d1d0-b732-4747-b661-1c281e240ff6" width="224" height="324" />
  <img src="https://github.com/user-attachments/assets/4f909a2b-acf4-4ee4-bc40-332998b256ee" width="224" height="324"/>
</p>

# ğŸ‘¥ Our Team
- [**Dr. Samer Khamaiseh** - Director of LAiSR Research Group](https://www.linkedin.com/in/samer-khamaiseh/)
- [**Deirdre Jost** - Research Assistant](https://www.linkedin.com/in/deirdre-jost-445822228/)
- [**Steven Chiacchira** - Research Assistant](https://www.linkedin.com/in/steven-chiacchira)
- [**Aibak Aljadayah** - Research Assistant](https://www.linkedin.com/in/aibak-aljadayah)
- [**Azib Farooq** - Research Assistant](https://www.linkedin.com/in/itsazibfarooq/)


## ğŸ“« Reach us 
This GitHub account serves as a hub for our ongoing projects, publications, and collaborations. We welcome your engagement and encourage you to explore the exciting frontiers of AI security with us!
[Contact us here](https://miamioh.edu/profiles/cec/samer-khamaiseh.html)





