# [AI Security Research Lab at Miami University](https://miamioh.edu/profiles/cec/samer-khamaiseh.html)

## 👋 **Welcome to the Laboratory of AI Security Research (LAiSR) at Miami University.**
The rapid proliferation of artificial intelligence (AI) has revolutionized our world, but it also brings forth critical security challenges. As organizations harness AI’s power, they must grapple with new vulnerabilities and potential risks. From automated cyberattacks to disinformation campaigns, the stakes are high.

## ❓ Why is **AI securtiy** research paramount?
- Emerging Threats: As AI systems become more pervasive, so do the risks. From adversarial attacks on machine learning models to privacy breaches, understanding and mitigating these threats is crucial. Researchers play a pivotal role in uncovering vulnerabilities and devising robust defenses.
- Safeguarding Critical Systems: AI is increasingly integrated into critical infrastructure, healthcare, finance, and defense. Ensuring the security of these systems is non-negotiable. Rigorous research helps prevent catastrophic failures and protects lives and livelihoods.
- Ethical Implications: AI decisions impact individuals and societies. Bias, fairness, and transparency are ethical concerns. Research informs guidelines and policies that promote responsible AI deployment, minimizing harm and maximizing benefits.

## 🎤 Who we are? 
**LAiSR** is a research group led by **Dr. Samer Khamaiseh**. We are passionate about exploring and addressing the evolving challenges within the realm of AI security. Our AI Research Laboratory is at the forefront of cutting-edge research to fortify AI models against adversarial attacks, enhance their robustness, and ensure their reliability in real-world scenarios.

## 🔎 Research Focus
- **Robustness:** We delve into techniques that make AI models resilient to perturbations, adversarial examples, and distribution shifts.
- **Security:** Exploring defenses against attacks, privacy preservation, and secure AI deployment.
- **AI Ethics:** Investigate fairness, bias mitigation, and transparency in AI systems.

## 🚀 Projects
### **Fool-X**
[Add descreption]
### **Image Patriot**
[Add descreption]
### **target-X**
[Add descreption]
### **ADT++**
A novel method for adversarial training.
### **VariousAttacks**
A novel method for adversarial training.

# 📸 Gallery
<p float="left">
  <img src="https://github.com/user-attachments/assets/4ba8d1d0-b732-4747-b661-1c281e240ff6" width="224" height="300" />
</p>

# 👥 Our Team
- [**Dr. Samer Khamaiseh** - Director of LAiSR Research Group](https://www.linkedin.com/in/samer-khamaiseh/)
- [**Deirdre Jost** - Research Assistant](https://www.linkedin.com/in/deirdre-jost-445822228/)
- [**Steven Chiacchira** - Research Assistant](https://www.linkedin.com/in/steven-chiacchira)
- [**Aibak Aljadayah** - Research Assistant](https://www.linkedin.com/in/aibak-aljadayah)
- [**Azib Farooq** - Research Assistant](https://www.linkedin.com/in/itsazibfarooq/)


## 📫 Reach us 
This GitHub account serves as a hub for our ongoing projects, publications, and collaborations. We welcome your engagement and encourage you to explore the exciting frontiers of AI security with us!
[Contact us here](https://miamioh.edu/profiles/cec/samer-khamaiseh.html)





